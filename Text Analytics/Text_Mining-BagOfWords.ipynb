{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"Karachi is one of the most congested city in the world.\"\n",
    "str2 = \"Karachi is the financial capital of Pakistan.\"\n",
    "str3 = \"Islamabad is the capital of Pakistan.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Karachi is one of the most congested city in the world.', 'Karachi is the financial capital of Pakistan.', 'Islamabad is the capital of Pakistan.']\n"
     ]
    }
   ],
   "source": [
    "strlist = [str1,str2,str3]                                                                                      #list of all three string elements\n",
    "print(strlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the', 'a', 'in', 'is', 'of'}\n"
     ]
    }
   ],
   "source": [
    "stopword = set(\"of the a is in\".split())                                                                        #define our own stop words (not i=use dictonary)\n",
    "print(stopword)                                                                                                 #print stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1.split()                                                                                                    #Tokenized sentence/ word by word split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Karachi', 'one', 'most', 'congested', 'city', 'world.']\n",
      "['Karachi', 'financial', 'capital', 'Pakistan.']\n",
      "['Islamabad', 'capital', 'Pakistan.']\n",
      "['Karachi one most congested city world.', 'Karachi financial capital Pakistan.', 'Islamabad capital Pakistan.']\n"
     ]
    }
   ],
   "source": [
    "s = []\n",
    "for str in strlist:                                                                                             #every string in string lst\n",
    "    s_list = [word for word in str.split() if word not in stopword]                                             #store all the words that are not stop words\n",
    "    print(s_list)\n",
    "    str_ = ' '.join(s_list)                                                                                     #join words in a sentence without stop words \n",
    "    s.append(str_) \n",
    "print(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'karachi': 5, 'one': 7, 'most': 6, 'congested': 2, 'city': 1, 'world': 9, 'financial': 3, 'capital': 0, 'pakistan': 8, 'islamabad': 4}\n"
     ]
    }
   ],
   "source": [
    "cnt_vectorizer = CountVectorizer()                                                                              #term frequency --> in 1/0 form (unigram)\n",
    "cnt_vectorizer.fit(s)                                                                                           #s= list after removing stop word     \n",
    "print(cnt_vectorizer.vocabulary_)                                                                               #print vocabulary --> total vocabulary = 1 (0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['capital', 'city', 'congested', 'financial', 'islamabad', 'karachi', 'most', 'one', 'pakistan', 'world']\n"
     ]
    }
   ],
   "source": [
    "print(cnt_vectorizer.get_feature_names())                                                                       #print in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 10)\n"
     ]
    }
   ],
   "source": [
    "vec1 = cnt_vectorizer.transform(s).toarray()                                                                    #size/dimension of Term Document Frequency (TDM)\n",
    "print(vec1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 0 1 1 1 0 1]\n",
      " [1 0 0 1 0 1 0 0 1 0]\n",
      " [1 0 0 0 1 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(vec1)                                                                                                     #Print vector --> no capital in sentence 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.20412415 0.        ]\n",
      " [0.20412415 1.         0.57735027]\n",
      " [0.         0.57735027 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "cs1 = cosine_similarity(vec1)                                                                                   #cosine similarity of the vector\n",
    "print(cs1)                                                                                                      #Highest similarity = 0.6 of sentence 2&3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.22176756638345\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "angle_in_radians = math.acos(0.20412415)\n",
    "print(math.degrees(angle_in_radians))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lahore second largest city Pakistan and an important financial center.\n"
     ]
    }
   ],
   "source": [
    "new_str = \"Lahore is the second largest city of Pakistan and an important financial center.\"                    #predict with which sentence is this similar\n",
    "\n",
    "n_list = [word for word in new_str.split() if word not in stopword]\n",
    "new_str = ' '.join(n_list)\n",
    "\n",
    "print(new_str)                                                                                                  #Sentence after removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 8)\t1\n"
     ]
    }
   ],
   "source": [
    "response = cnt_vectorizer.transform([new_str])  \n",
    "print(response)                                                                                                 #1st, 3rd & 8th (from above 3 sentence --> train) word exist in this sentence  **won't add any new word from test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 0, 0, 0, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.toarray()                                                                                               #similarity on the words that are part of dictinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23570226 0.57735027 0.33333333]]\n"
     ]
    }
   ],
   "source": [
    "answer = cosine_similarity(response,vec1)\n",
    "print(answer)                                                                                                   #highest similarity with 2nd sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the maximum is  0.5773502691896258\n",
      "1 Karachi is the financial capital of Pakistan.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ans = answer[0]\n",
    "print(\"the maximum is \", max(ans))                                                                              #highest similarity\n",
    "\n",
    "b = np.argmax(ans)\n",
    "print(b, strlist[b])                                                                                            #sentence closest to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['capital', 'capital pakistan', 'city', 'city world', 'congested', 'congested city', 'financial', 'financial capital', 'islamabad', 'islamabad capital', 'karachi', 'karachi financial', 'karachi one', 'most', 'most congested', 'one', 'one most', 'pakistan', 'world']\n"
     ]
    }
   ],
   "source": [
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2))                                                         #BiGram --> pair of consective words + uniGram\n",
    "bigram_vectorizer.fit(s)                                                                                        #after stop word removed\n",
    "print(bigram_vectorizer.get_feature_names())                                                                    #sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 19)\n"
     ]
    }
   ],
   "source": [
    "vec2 = bigram_vectorizer.transform(s).toarray()\n",
    "print(vec2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.11396058 0.        ]\n",
      " [0.11396058 1.         0.50709255]\n",
      " [0.         0.50709255 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "cs2 = cosine_similarity(vec2)\n",
    "print(cs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['capital', 'capital pakistan', 'karachi', 'most', 'most congested', 'one', 'one most', 'pakistan']\n"
     ]
    }
   ],
   "source": [
    "#If not None, build a vocabulary that only consider the top max_features ordered by term frequency \n",
    "#across the corpus.\n",
    "bigram_vectorizer2 = CountVectorizer(ngram_range=(1, 2), max_features=8)                                                #lock feature set --> based on term frequency\n",
    "bigram_vectorizer2.fit(s)\n",
    "print(bigram_vectorizer2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8)\n"
     ]
    }
   ],
   "source": [
    "vec3 = bigram_vectorizer2.transform(s).toarray()\n",
    "print(vec3.shape)                                                                                                       #8 max features = 8 words = 8 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.        0.2236068 0.       ]\n",
      " [0.2236068 1.        0.8660254]\n",
      " [0.        0.8660254 1.       ]]\n"
     ]
    }
   ],
   "source": [
    "cs3 = cosine_similarity(vec3)\n",
    "print(cs3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
